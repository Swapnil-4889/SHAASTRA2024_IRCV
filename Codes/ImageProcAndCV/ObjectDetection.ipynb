{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection using YOLO v8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Created for the **Integrated Robotics and Computer Vision Workshop** for **Shaastra 2024**\n",
    "\n",
    "- This notebook is a part of the **Computer Vision** module\n",
    "\n",
    "- Workshop Presenters:\n",
    "    - Raghav Jangid [ME20B143]\n",
    "    - Swapnil Mehta [ME20B183]\n",
    "    - Rahul [ME20B145]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import morphology\n",
    "from skimage.feature import corner_harris,corner_peaks\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display an image -\n",
    "\n",
    "def show_image(img,title):\n",
    "    cv2.imshow(title,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the YOLO v8 model to detect boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.228, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Cardboardbox-detection-1 to yolov8:: 100%|██████████| 3743/3743 [00:02<00:00, 1803.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Cardboardbox-detection-1 in yolov8:: 100%|██████████| 368/368 [00:00<00:00, 882.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Importing ultralytics and roboflow for YOLO v8 mode and datasets -\n",
    "\n",
    "# Ultralytics for using YOLO model\n",
    "#!pip install ultralytics      \n",
    "\n",
    "# Roboflow for downloading training datasets\n",
    "#!pip install roboflow         \n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"X9AIXoNO9Q8uxUXDCPXY\")\n",
    "project = rf.workspace(\"directed-technologies\").project(\"cardboardbox-detection\")\n",
    "dataset = project.version(1).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=50 imgsz=800 plots=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The training process is not included in this notebook as it would take a lot of time to train on the dataset.\n",
    ">\n",
    "> Therefore, we will be using a pre-trained model for the detection task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"X9AIXoNO9Q8uxUXDCPXY\")\n",
    "project = rf.workspace().project(\"cardboardbox-detection\")\n",
    "model = project.version(1).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_img = cv2.imread(\"Boxes.jpg\")\n",
    "\n",
    "show_image(boxes_img,\"Boxes\")   # Displaying the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 40\n",
    "overlap = 30\n",
    "model.predict(\"Boxes.jpg\",confidence=80,overlap=30).save(\"prediction_boxes.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The above model does the prediction on the image and returns the bounding boxes and the class of the object detected which are above the **confidence imterval**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_boxes_img = cv2.imread(\"prediction_boxes.jpg\")\n",
    "\n",
    "show_image(detected_boxes_img,\"Boxes Detected\")  # Displaying the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = model.predict(\"Boxes_3.jpg\",confidence=80,overlap=30).json()[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_boxes = []\n",
    "for i in range(len(bounding_boxes)) :\n",
    "    x = int(bounding_boxes[i]['x'])\n",
    "    y = int(bounding_boxes[i]['y'])\n",
    "    height = int(bounding_boxes[i]['height'])\n",
    "    width = int(bounding_boxes[i]['width'])\n",
    "    detected_boxes.append(boxes_img[y-height//2-20:y+height//2+20,x-width//2-20:x+width//2+20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid the problem of lighting conditions, we use a range of colors instead of a single color\n",
    "img = detected_boxes[0]\n",
    "\n",
    "#box_color_range = [(60,110,150),(130,180,220)]  # Color range of the boxes\n",
    "box_color_range = [(60,110,150),(130,180,240)]\n",
    "lower = np.array(box_color_range[0],dtype=np.uint8)  # Lower bound of the color range\n",
    "upper = np.array(box_color_range[1],dtype=np.uint8)  # Upper bound of the color range\n",
    "\n",
    "box_mask = cv2.inRange(img,lower,upper)  # Masking the image\n",
    "\n",
    "box_masked_img = cv2.bitwise_and(img,img,mask=box_mask)  # Masked image\n",
    "show_image(box_mask,'masked image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 10\n",
    "\n",
    "# Create a circular kernel using skimage.morphology.disk\n",
    "#circular_kernel = morphology.disk(side)\n",
    "circular_kernel = np.ones((side,side),np.uint8)\n",
    "# Perform morphological dilation using binary_dilation\n",
    "dilated_image = cv2.dilate(box_mask,circular_kernel,iterations=1)\n",
    "#dilated_image = dilated_image.astype(np.uint)\n",
    "#show_image(dilated_image,'dialated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image = cv2.GaussianBlur(dilated_image,(side,side),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_image = corner_harris(blurred_image)\n",
    "#coords = corner_peaks(measure_image, min_distance=5)\n",
    "show_image(measure_image,'measure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_img_gray = cv2.cvtColor(box_masked_img,cv2.COLOR_BGR2GRAY)  # Converting the image to grayscale\n",
    "\n",
    "boxes_canny = cv2.Canny(box_mask,90,100)  # Detecting edges in the image\n",
    "\n",
    "show_image(boxes_canny,'canny edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
