{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Image Processing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Created for the **Integrated Robotics and Computer Vision Workshop** for **Shaastra 2024**\n",
    "\n",
    "- This notebook is a part of the **Computer Vision** module\n",
    "\n",
    "- Workshop Trainers:\n",
    "    - Raghav Jangid [ME20B143]\n",
    "    - Swapnil Mehta [ME20B183]\n",
    "    - Rahul [ME20B145]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Sample Images & Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image 1 - Lena -\n",
    "img1 = cv2.imread('Img1.jpg')\n",
    "#img1 = cv2.imread('Img1.jpeg', cv2.IMREAD_GRAYSCALE) # Grayscale\n",
    "\n",
    "# Image 2 -\n",
    "img2 = cv2.imread('Img2.jpeg')\n",
    "# img2 = cv2.imread('Img2.jpeg', cv2.IMREAD_GRAYSCALE) # Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing Image 1 -\n",
    "cv2.imshow('Image 1', img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to show images -\n",
    "\n",
    "def show_image(img,title):\n",
    "    cv2.imshow(title,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a Video -\n",
    "vid = cv2.VideoCapture('Video1.mp4')    \n",
    "\n",
    "# Playing the video -\n",
    "while True :\n",
    "    success, img = vid.read()   # Reading the video frame by frame\n",
    "\n",
    "    if success :\n",
    "        cv2.imshow('Video',img)    # Showing each video frame\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):    # Pressing 'q' to quit\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    else :\n",
    "        cv2.destroyAllWindows()   # Closes the window after playing the video once\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing Webcam Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(1)  # Importing the webcam feed\n",
    "\n",
    "# Setting the frame width & height -\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "vid.set(3, frameWidth)\n",
    "vid.set(4, frameHeight)\n",
    "\n",
    "while True :\n",
    "    success, img = vid.read()  # Reading the video frame by frame\n",
    "\n",
    "    if success :\n",
    "        neg_img = 255 - img\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # Converting the video to HSV\n",
    "        cv2.imshow('Video', img)\n",
    "\n",
    "        if cv2.waitKey(1) != -1:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    else :\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizing & Reshaping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.8\n",
    "\n",
    "img = cv2.imread('Img1.jpg')\n",
    "\n",
    "new_width = int(img.shape[1]*scale)\n",
    "new_height = int(img.shape[0]*scale)\n",
    "\n",
    "# Scaling the image -\n",
    "new_img = cv2.resize(img,(new_width,new_height))\n",
    "# new_img = cv2.resize(img,(0,0),fx=scale,fy=scale) # Another way to scale the images\n",
    "show_image(new_img,'resized image')\n",
    "\n",
    "# Custom shape -\n",
    "new_width = 640\n",
    "new_height = 480\n",
    "\n",
    "new_img = cv2.resize(img,(new_width,new_height))\n",
    "\n",
    "show_image(new_img,'resized image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_img = img[int(0.2*img.shape[0]):int(0.8*img.shape[0]),\n",
    "              int(0.2*img.shape[1]):int(0.8*img.shape[1])]\n",
    "\n",
    "show_image(new_img,'cropped image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default color space - BGR (Blue, Green, Red)\n",
    "\n",
    "# Grayscale -\n",
    "new_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "show_image(new_img,'gray')\n",
    "\n",
    "# RGB -\n",
    "new_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "show_image(new_img,'rgb')\n",
    "\n",
    "# HSV -\n",
    "new_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "show_image(new_img,'hcv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Translation & Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation -\n",
    "\n",
    "x = 100   # Translation along x-axis\n",
    "y = 0   # Translation along y-axis\n",
    "\n",
    "dim = (img.shape[1],img.shape[0])\n",
    "# Translation matrix -\n",
    "T_mat = np.float32([[1,0,x],[0,1,y]])\n",
    "\n",
    "# Translating the image -\n",
    "Translated_img = cv2.warpAffine(img,T_mat,dim)  # Translating the image\n",
    "\n",
    "show_image(Translated_img,'translated image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation -\n",
    "\n",
    "dim = (img.shape[1],img.shape[0])\n",
    "\n",
    "pnt_rot = (img.shape[1]//2,img.shape[0]//2) # Point of rotation\n",
    "\n",
    "angle = 45   # Angle of rotation\n",
    "\n",
    "scale = 2  # Scales the image\n",
    "\n",
    "rot_mat = cv2.getRotationMatrix2D(pnt_rot,angle,scale)  # Generates rotation matrix\n",
    "\n",
    "rotated_img = cv2.warpAffine(img,rot_mat,dim)  # Rotating the image\n",
    "\n",
    "show_image(rotated_img,'rotated image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.41421356,    1.41421356, -234.03867197],\n",
       "       [  -1.41421356,    1.41421356,  128.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying gaussian blur filter on the image -\n",
    "\n",
    "kernel_size = (21,21)  # Size of the filter kernel convloving the image\n",
    "\n",
    "sigma_X = 0 #10  # Standard deviation along x-axis\n",
    "\n",
    "blurred_img = cv2.GaussianBlur(img,kernel_size,sigma_X)  # Blurring the image\n",
    "\n",
    "show_image(blurred_img,'blurred image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the above cell, the `kernel size` determines the amount of blurring. The larger the kernel size, the more the blurring. It must be an **odd number**.\n",
    "\n",
    "- The `sigmaX` parameter determines the amount of blurring in the x-direction. The larger the value, the more the blurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source points\n",
    "src_pnts = np.float32([[0,0],\n",
    "                       [img.shape[1],0],\n",
    "                       [0,img.shape[0]],\n",
    "                       [img.shape[1],img.shape[0]]])  \n",
    "\n",
    "# Destination points\n",
    "dst_pnts = np.float32([[0,int(0.1*img.shape[0])],\n",
    "                       [int(0.9*img.shape[1]),0],\n",
    "                       [int(0.2*img.shape[1]),img.shape[0]-1],\n",
    "                       [img.shape[1]-1,int(0.6*img.shape[0])]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above cell shows the `source points` and `destination points` for the warp transformation.\n",
    "- The transformation occurs by mapping the source points (in this case the corners of the image) to the destination points and thus *warping* the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (img.shape[1],img.shape[0])  # Dimensions of the image\n",
    "\n",
    "warp_mat = cv2.getPerspectiveTransform(src_pnts,dst_pnts)   # Generates the warp matrix\n",
    "\n",
    "warped_img = cv2.warpPerspective(img,warp_mat,dim)  # Warping the image\n",
    "\n",
    "show_image(warped_img,'warped image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Shapes and Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_copy = img.copy()\n",
    "\n",
    "# Drawing a rectangle on the image -\n",
    "left_top = (100,40)\n",
    "\n",
    "bottom_right = (430,400)\n",
    "\n",
    "color = (0,255,255)  # Yellow\n",
    "\n",
    "thickess = 5\n",
    "cv2.rectangle(img_copy,left_top,bottom_right,color,thickess)  # Drawing the rectangle\n",
    "\n",
    "show_image(img_copy,'rectangle')\n",
    "\n",
    "# Adding text to the image -\n",
    "\n",
    "Txt = \"This image has a yellow rectangle\"\n",
    "\n",
    "start_pnt = (20,25)  # Starting point of the text\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX  # Font style\n",
    "font_size = 0.8\n",
    "font_color = (255,0,0)  # Red\n",
    "thickess = 2\n",
    "\n",
    "cv2.putText(img_copy,Txt,start_pnt,font,font_size,font_color,thickess)  # Adding text to the image\n",
    "\n",
    "show_image(img_copy,'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting and Merging Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b, g, r = cv2.split(img2) # Splitting the image into its channels\n",
    "\n",
    "# Creating a blank image of the same size as the original image -\n",
    "blue_img, green_img, red_img = np.zeros_like(img2), np.zeros_like(img2), np.zeros_like(img2) \n",
    "\n",
    "blue_img[:,:,0] = b  # Blue channel\n",
    "show_image(blue_img,'Blue')\n",
    "green_img[:,:,1] = g  # Green channel\n",
    "show_image(green_img,'Green')\n",
    "\n",
    "red_img[:,:,2] = r  # Red channel\n",
    "show_image(red_img,'Red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting edges in an image\n",
    "\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  # Converting the image to grayscale\n",
    "\n",
    "cannyEdge = cv2.Canny(img,100,200)  # Detecting edges in the image\n",
    "\n",
    "show_image(cannyEdge,'canny edge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here, the function `cv2.Canny()` takes 2 numbers in the input which are the **minimum** and **maximum** threshold intensity values for detecting the edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we detect **different shapes** and draw their outlines on the original image.\n",
    "\n",
    "- For this, we first convert the image into grayscale, then find the edges using the technique shown above and then find the contours of the shapes.\n",
    "\n",
    "- Finally, we draw these contours on the original image to highlight the shape outlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_img = cv2.imread('Shapes.jpg')\n",
    "\n",
    "shapes_img_gray = cv2.cvtColor(shapes_img,cv2.COLOR_BGR2GRAY)  # Converting the image to grayscale\n",
    "\n",
    "cannyEdge = cv2.Canny(shapes_img_gray,100,200)  # Detecting edges in the image\n",
    "\n",
    "show_image(cannyEdge,'canny edge')\n",
    "\n",
    "# Contour detection -\n",
    "\n",
    "contours, hierarchy = cv2.findContours(cannyEdge,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)  # Detecting contours in the image\n",
    "\n",
    "# Drawing contours on the image -\n",
    "for contour in contours :\n",
    "    blueColor = (255,0,0)\n",
    "    contourIndex = -1\n",
    "    thickness = 3\n",
    "    cv2.drawContours(shapes_img,contours,contourIndex,blueColor,thickness)  # Drawing the contours\n",
    "\n",
    "show_image(shapes_img,'contours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Application : Detecting Boxes on a Conveyor Belt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we will attempt to detect the boxes on a conveyor belt and then draw their outlines on the original image.\n",
    "\n",
    "- Here are the steps we follow to accomplish this task :\n",
    "\n",
    "    1. Identify the `color of the boxes` and create a *mask* for them\n",
    "    \n",
    "    2. Apply the masking on the original image to get the `boxes only image`\n",
    "    3. Convert the image to *grayscale*\n",
    "    4. Find the edges using the *Canny edge detection* technique\n",
    "    5. Find the contours of the shapes\n",
    "    6. Draw the contours on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_img = cv2.imread('Boxes.jpg')  # Importing the image\n",
    "\n",
    "# Identified color of the boxes using the color picker tool in paint - [B: 75, G: 126, R: 166]\n",
    "\n",
    "# To avoid the problem of lighting conditions, we use a range of colors instead of a single color\n",
    "box_color_range = [(60,110,150),(130,180,220)]  # Color range of the boxes\n",
    "\n",
    "lower = np.array(box_color_range[0],dtype=np.uint8)  # Lower bound of the color range\n",
    "upper = np.array(box_color_range[1],dtype=np.uint8)  # Upper bound of the color range\n",
    "\n",
    "box_mask = cv2.inRange(boxes_img,lower,upper)  # Masking the image\n",
    "\n",
    "box_masked_img = cv2.bitwise_and(boxes_img,boxes_img,mask=box_mask)  # Masked image\n",
    "show_image(box_masked_img,'masked image')\n",
    "\n",
    "boxes_img_gray = cv2.cvtColor(box_masked_img,cv2.COLOR_BGR2GRAY)  # Converting the image to grayscale\n",
    "\n",
    "boxes_canny = cv2.Canny(boxes_img_gray,150,255)  # Detecting edges in the image\n",
    "\n",
    "show_image(boxes_canny,'canny edge')\n",
    "\n",
    "# Contours -\n",
    "\n",
    "# Finding the contours in the image\n",
    "contours,hierarchy = cv2.findContours(boxes_canny,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE) \n",
    "\n",
    "for contour in contours :\n",
    "    blueColor = (255,0,0)\n",
    "    contourIndex = -1\n",
    "    thickness = 3\n",
    "    cv2.drawContours(boxes_img,contours,contourIndex,blueColor,thickness)  # Drawing the contours\n",
    "\n",
    "show_image(boxes_img,'contours image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resourses :\n",
    "\n",
    "- OpenCV Documentation : https://docs.opencv.org/4.5.2/d6/d00/tutorial_py_root.html\n",
    "\n",
    "- Geeks for Geeks Tutorials : https://www.geeksforgeeks.org/opencv-python-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
